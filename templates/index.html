<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Whisper Speech to Text with History</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet">


    <style>
        body {
            padding: 2rem;
            background: linear-gradient(to bottom right, #f0f2f5, #ffffff);
            font-family: "Segoe UI", sans-serif;
        }

        #history {
            max-height: 300px;
            overflow-y: auto;
            background: white;
            border: 1px solid #dee2e6;
            padding: 1rem;
            border-radius: 0.375rem;
        }

        .transcription-new {
            background-color: #d1e7dd;
            padding: 1rem;
            border-radius: 0.375rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .transcription-old {
            border-bottom: 1px solid #dee2e6;
            padding: 0.5rem 0;
            font-size: 0.95rem;
            color: #495057;
        }

        #silenceTimer {
            font-size: 1rem;
            font-weight: bold;
            color: #dc3545;
            margin-top: 0.5rem;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1 class="mb-4">Whisper Speech to Text (English)</h1>

        <div class="mb-3 d-flex flex-wrap gap-2">
            <button id="recordBtn" class="btn btn-primary">
                <i class="bi bi-mic-fill"></i> Manual Record
            </button>
            <button id="autoRecordBtn" class="btn btn-secondary">
                <i class="bi bi-mic"></i> Auto Record
            </button>
            <button id="clearBtn" class="btn btn-outline-danger">
                <i class="bi bi-trash"></i> Clear History
            </button>
            <button id="exportBtn" class="btn btn-outline-success">
                <i class="bi bi-download"></i> Export Text
            </button>
            <div id="status" class="ms-3 text-muted align-self-center fw-medium">ðŸŸ¡ Idle</div>
        </div>


        <div class="mt-2 w-100">
            <div class="progress" style="height: 20px;">
                <div id="silenceProgressBar" class="progress-bar bg-danger" role="progressbar" style="width: 0%">
                    Waiting...</div>
            </div>
        </div>


        <div id="currentTranscription" class="transcription-new" style="display:none;"></div>

        <h5>History</h5>
        <div id="history" class="mb-5"></div>
    </div>

    <script>
        let recordBtn = document.getElementById("recordBtn");
        let autoRecordBtn = document.getElementById("autoRecordBtn");
        let clearBtn = document.getElementById("clearBtn");
        let exportBtn = document.getElementById("exportBtn");
        let status = document.getElementById("status");
        let silenceTimer = document.getElementById("silenceTimer");
        let currentTranscriptionEl = document.getElementById("currentTranscription");
        let historyEl = document.getElementById("history");

        let mediaRecorder, audioChunks = [], silenceTimeout, silenceCountdown;
        let audioContext, analyser, dataArray;

        let history = [];

        function addToHistory(text) {
            if (!text.trim()) return;
            currentTranscriptionEl.style.display = "block";
            currentTranscriptionEl.textContent = text;

            let div = document.createElement("div");
            div.className = "transcription-old";
            div.textContent = text;
            historyEl.appendChild(div);
            historyEl.scrollTop = historyEl.scrollHeight;
            history.push(text);
        }

        function sendToBackend(blob) {
            let reader = new FileReader();
            reader.readAsDataURL(blob);
            reader.onloadend = async () => {
                const response = await fetch("/transcribe", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ audio: reader.result })
                });
                const data = await response.json();
                addToHistory(data.transcription);
                status.textContent = `âœ… Transcription complete.`;
                silenceTimer.textContent = "";
            };
        }

        recordBtn.onclick = async () => {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                recordBtn.textContent = "Start Manual Recording";
                status.textContent = "Stopped recording.";
            } else {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioChunks = [];
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
                mediaRecorder.onstop = () => {
                    let blob = new Blob(audioChunks, { type: "audio/wav" });
                    status.textContent = "Processing audio...";
                    sendToBackend(blob);
                };

                mediaRecorder.start();
                recordBtn.textContent = "Stop Manual Recording";
                status.textContent = "Recording...";
            }
        };

        autoRecordBtn.onclick = async () => {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioChunks = [];
            mediaRecorder = new MediaRecorder(stream);
            const source = (audioContext = new AudioContext()).createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            source.connect(analyser);
            dataArray = new Uint8Array(analyser.frequencyBinCount);

            mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
            mediaRecorder.onstop = () => {
                let blob = new Blob(audioChunks, { type: "audio/wav" });
                status.textContent = "Processing auto-recorded audio...";
                sendToBackend(blob);
                clearTimeout(silenceTimeout);
                cancelAnimationFrame(silenceCountdown);
            };

            mediaRecorder.start();
            status.textContent = "Auto recording... If you are silent for 3 seconds, recording will stop automatically.";
            detectSilence();
        };
        function detectSilence() {
            let silentDuration = 0;
            let silenceThreshold = 5;  // lower = more sensitive
            let checkInterval = 100;   // ms
            let maxSilentMs = 3000;    // 3 seconds
            const progressBar = document.getElementById("silenceProgressBar");

            progressBar.style.width = "0%";
            progressBar.textContent = "Listening...";
            progressBar.classList.remove("bg-success");
            progressBar.classList.add("bg-danger");

            let intervalId = setInterval(() => {
                analyser.getByteFrequencyData(dataArray);
                let avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

                if (avg < silenceThreshold) {
                    silentDuration += checkInterval;
                    let percent = (silentDuration / maxSilentMs) * 100;
                    progressBar.style.width = `${Math.min(percent, 100)}%`;
                    progressBar.textContent = `Silent: ${(silentDuration / 1000).toFixed(1)}s`;

                    if (silentDuration >= maxSilentMs) {
                        clearInterval(intervalId);
                        progressBar.textContent = "Stopped";
                        progressBar.classList.remove("bg-danger");
                        progressBar.classList.add("bg-success");
                        mediaRecorder.stop();
                        audioContext.close();
                    }
                } else {
                    silentDuration = 0;
                    progressBar.style.width = `0%`;
                    progressBar.textContent = "Listening...";
                }
            }, checkInterval);
        }


        clearBtn.onclick = () => {
            history = [];
            historyEl.innerHTML = "";
            currentTranscriptionEl.style.display = "none";
            status.textContent = "History cleared.";
        };

        exportBtn.onclick = () => {
            const text = history.join("\n\n");
            const blob = new Blob([text], { type: "text/plain" });
            const link = document.createElement("a");
            link.href = URL.createObjectURL(blob);
            link.download = "transcription_history.txt";
            link.click();
        };
    </script>

</body>

</html>